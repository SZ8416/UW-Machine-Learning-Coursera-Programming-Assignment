{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locality Sensitive Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locality Sensitive Hashing (LSH) provides for a fast, efficient approximate nearest neighbor search. The algorithm scales well with respect to the number of data points as well as dimensions.\n",
    "\n",
    "In this assignment, you will\n",
    "* Implement the LSH algorithm for approximate nearest neighbor search\n",
    "* Examine the accuracy for different documents by comparing against brute force search, and also contrast runtimes\n",
    "* Explore the role of the algorithm’s tuning parameters in the accuracy of the method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note to Amazon EC2 users**: To conserve memory, make sure to stop all the other notebooks before running this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block will check if you have the correct version of GraphLab Create. Any version later than 1.8.5 will do. To upgrade, read [this page](https://turi.com/download/upgrade-graphlab-create.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np                                             # dense matrices                                                 # see below for install instruction\n",
    "from scipy.sparse import csr_matrix                            # sparse matrices\n",
    "from sklearn.metrics.pairwise import pairwise_distances        # pairwise distances\n",
    "from copy import copy                                          # deep copies\n",
    "import matplotlib.pyplot as plt                                # plotting\n",
    "%matplotlib inline\n",
    "\n",
    "'''compute norm of a sparse vector\n",
    "   Thanks to: Jaiyam Sharma'''\n",
    "def norm(x):\n",
    "    sum_sq=x.dot(x.T)\n",
    "    norm=np.sqrt(sum_sq)\n",
    "    return(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = pd.read_csv('people_wiki.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract TF-IDF matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first use GraphLab Create to compute a TF-IDF representation for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    data = loader['data']\n",
    "    indices = loader['indices']\n",
    "    indptr = loader['indptr']\n",
    "    shape = loader['shape']\n",
    "    return csr_matrix((data, indices, indptr), shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = load_sparse_csr('people_wiki_tf_idf.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('people_wiki_map_index_to_word.json', 'r') as f: # Reads the list of most frequent words\n",
    "    map_index_to_word = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check passed correctly!\n"
     ]
    }
   ],
   "source": [
    "assert corpus.shape == (59071, 547979)\n",
    "print('Check passed correctly!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an LSH model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSH performs an efficient neighbor search by randomly partitioning all reference data points into different bins. Today we will build a popular variant of LSH known as random binary projection, which approximates cosine distance. There are other variants we could use for other choices of distance metrics.\n",
    "\n",
    "The first step is to generate a collection of random vectors from the standard Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_vectors(num_vector, dim):\n",
    "    '''对于维度为dim的数据集，随机产生n条分割线'''\n",
    "    return np.random.randn(dim, num_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize these Gaussian random vectors, let's look at an example in low-dimensions.  Below, we generate 3 random vectors each of dimension 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  0.40015721,  0.97873798],\n",
       "       [ 2.2408932 ,  1.86755799, -0.97727788],\n",
       "       [ 0.95008842, -0.15135721, -0.10321885],\n",
       "       [ 0.4105985 ,  0.14404357,  1.45427351],\n",
       "       [ 0.76103773,  0.12167502,  0.44386323]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate 3 random vectors of dimension 5, arranged into a single 5 x 3 matrix.\n",
    "np.random.seed(0) # set seed=0 for consistent results\n",
    "generate_random_vectors(num_vector=3, dim=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now generate random vectors of the same dimensionality as our vocubulary size (547979).  Each vector can be used to compute one bit in the bin encoding.  We generate 16 vectors, leading to a 16-bit encoding of the bin index for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(547979, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate 16 random vectors of dimension 547979\n",
    "np.random.seed(0)\n",
    "random_vectors = generate_random_vectors(num_vector=16, dim=547979)\n",
    "random_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we partition data points into bins. Instead of using explicit loops, we'd like to utilize matrix operations for greater efficiency. Let's walk through the construction step by step.\n",
    "\n",
    "We'd like to decide which bin document 0 should go. Since 16 random vectors were generated in the previous cell, we have 16 bits to represent the bin index. The first bit is given by the sign of the dot product between the first random vector and the document's TF-IDF vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = corpus[0, :] # vector of tf-idf values for document 0\n",
    "doc.dot(random_vectors[:, 0]) >= 0 # True if positive sign; False if negative sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, the second bit is computed as the sign of the dot product between the second random vector and the document vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.dot(random_vectors[:, 1]) >= 0 # True if positive sign; False if negative sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute all of the bin index bits at once as follows. Note the absence of the explicit `for` loop over the 16 vectors. Matrix operations let us batch dot-product computation in a highly efficent manner, unlike the `for` loop construction. Given the relative inefficiency of loops in Python, the advantage of matrix operations is even greater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True, False, False, False,  True,  True, False,  True,\n",
       "         True,  True, False, False,  True, False,  True]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.dot(random_vectors) >= 0 # should return an array of 16 True/False bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(doc.dot(random_vectors) >= 0, dtype=int) # display index bits in 0/1's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All documents that obtain exactly this vector will be assigned to the same bin. We'd like to repeat the identical operation on all documents in the Wikipedia dataset and compute the corresponding bin indices. Again, we use matrix operations  so that no explicit loop is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True, False, False, False,  True,  True, False,  True,\n",
       "         True,  True, False, False,  True, False,  True],\n",
       "       [ True, False, False, False,  True,  True, False,  True,  True,\n",
       "        False,  True, False,  True, False, False,  True]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0:2].dot(random_vectors) >= 0 # compute bit indices of first two documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True, False, ...,  True, False,  True],\n",
       "       [ True, False, False, ..., False, False,  True],\n",
       "       [False,  True, False, ...,  True, False,  True],\n",
       "       ...,\n",
       "       [ True,  True, False, ...,  True,  True,  True],\n",
       "       [False,  True,  True, ...,  True, False,  True],\n",
       "       [ True, False,  True, ..., False, False,  True]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.dot(random_vectors) >= 0 # compute bit indices of ALL documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost done! To make it convenient to refer to individual bins, we convert each binary bin index into a single integer: \n",
    "```\n",
    "Bin index                      integer\n",
    "[0,0,0,0,0,0,0,0,0,0,0,0]   => 0\n",
    "[0,0,0,0,0,0,0,0,0,0,0,1]   => 1\n",
    "[0,0,0,0,0,0,0,0,0,0,1,0]   => 2\n",
    "[0,0,0,0,0,0,0,0,0,0,1,1]   => 3\n",
    "...\n",
    "[1,1,1,1,1,1,1,1,1,1,0,0]   => 65532\n",
    "[1,1,1,1,1,1,1,1,1,1,0,1]   => 65533\n",
    "[1,1,1,1,1,1,1,1,1,1,1,0]   => 65534\n",
    "[1,1,1,1,1,1,1,1,1,1,1,1]   => 65535 (= 2^16-1)\n",
    "```\n",
    "By the [rules of binary number representation](https://en.wikipedia.org/wiki/Binary_number#Decimal), we just need to compute the dot product between the document vector and the vector consisting of powers of 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True False False False  True  True False  True  True  True False\n",
      "  False  True False  True]]\n",
      "[32768 16384  8192  4096  2048  1024   512   256   128    64    32    16\n",
      "     8     4     2     1]\n",
      "[50917]\n"
     ]
    }
   ],
   "source": [
    "doc = corpus[0, :]  # first document\n",
    "index_bits = (doc.dot(random_vectors) >= 0)\n",
    "powers_of_two = (2**np.arange(15, -1, -1))\n",
    "print(index_bits)\n",
    "print(powers_of_two)\n",
    "print(index_bits.dot(powers_of_two))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's the dot product again, we batch it with a matrix operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50917, 36265, 19365, ..., 52983, 27589, 41449], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_bits = corpus.dot(random_vectors) >= 0\n",
    "index_bits.dot(powers_of_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This array gives us the integer index of the bins for all documents.\n",
    "\n",
    "Now we are ready to complete the following function. Given the integer bin indices for the documents, you should compile a list of document IDs that belong to each bin. Since a list is to be maintained for each unique bin index, a dictionary of lists is used.\n",
    "\n",
    "1. Compute the integer bin indices. This step is already completed.\n",
    "2. For each document in the dataset, do the following:\n",
    "   * Get the integer bin index for the document.\n",
    "   * Fetch the list of document ids associated with the bin; if no list yet exists for this bin, assign the bin an empty list.\n",
    "   * Add the document id to the end of the list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lsh(data, num_vector=16, seed=None):\n",
    "    '''训练LSH模型，输出模型'''\n",
    "    # 根据数据集确定训练集维度\n",
    "    dim = data.shape[1]\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    # 产生n条随机分割线\n",
    "    random_vectors = generate_random_vectors(num_vector, dim)\n",
    "    \n",
    "    powers_of_two = 2**np.arange(num_vector-1, -1, -1)\n",
    "  \n",
    "    table = {}\n",
    "    \n",
    "    # 确定每个data point的分组(0-1)\n",
    "    bin_index_bits = (data.dot(random_vectors) >= 0)\n",
    "    powers_of_two = 2**np.arange(num_vector-1, -1, -1)\n",
    "    # 确定每个data point的分组(数字)\n",
    "    bin_indices = bin_index_bits.dot(powers_of_two)\n",
    "    \n",
    "    # 对于每一个data，进行分bin\n",
    "    for data_index, bin_index in enumerate(bin_indices):\n",
    "        if bin_index not in table:\n",
    "            # 如果当前的bin还没有数据，设置空bin\n",
    "            table[bin_index] = []\n",
    "            # 将数据添加到bin中\n",
    "        table[bin_index].append(data_index) \n",
    "    # 输出模型：数据集、bin索引、bin中数据点、分割线\n",
    "    model = {'data': data,\n",
    "             'bin_index_bits': bin_index_bits,\n",
    "             'bin_indices': bin_indices,\n",
    "             'table': table,\n",
    "             'random_vectors': random_vectors,\n",
    "             'num_vector': num_vector}\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<59071x547979 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10379283 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed!\n"
     ]
    }
   ],
   "source": [
    "model = train_lsh(corpus, num_vector=16, seed=143)\n",
    "table = model['table']\n",
    "if 0 in table and table[0] == [39583] and \\\n",
    "   143 in table and table[143] == [19693, 28277, 29776, 30399]:\n",
    "    print('Passed!')\n",
    "else:\n",
    "    print('Check your code.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note.** We will be using the model trained here in the following sections, unless otherwise indicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at some documents and see which bins they fall into."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35817</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Barack_Obama&gt;</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>barack hussein obama ii brk husen bm born augu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              URI          name  \\\n",
       "35817  <http://dbpedia.org/resource/Barack_Obama>  Barack Obama   \n",
       "\n",
       "                                                    text  \n",
       "35817  barack hussein obama ii brk husen bm born augu...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki[wiki['name'] == 'Barack Obama']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. What is the document `id` of Barack Obama's article?\n",
    "\n",
    "**Quiz Question**. Which bin contains Barack Obama's article? Enter its integer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50194"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['bin_indices'][35817]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from the previous assignment that Joe Biden was a close neighbor of Barack Obama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24478</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Joe_Biden&gt;</td>\n",
       "      <td>Joe Biden</td>\n",
       "      <td>joseph robinette joe biden jr dosf rbnt badn b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           URI       name  \\\n",
       "24478  <http://dbpedia.org/resource/Joe_Biden>  Joe Biden   \n",
       "\n",
       "                                                    text  \n",
       "24478  joseph robinette joe biden jr dosf rbnt badn b...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki[wiki['name'] == 'Joe Biden']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. Examine the bit representations of the bins containing Barack Obama and Joe Biden. In how many places do they agree?\n",
    "\n",
    "1. 16 out of 16 places (Barack Obama and Joe Biden fall into the same bin)\n",
    "2. 14 out of 16 places\n",
    "3. 12 out of 16 places\n",
    "4. 10 out of 16 places\n",
    "5. 8 out of 16 places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False, False,  True, False, False, False,\n",
       "       False, False,  True, False, False,  True, False])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['bin_index_bits'][35817]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False,  True, False, False, False,\n",
       "       False, False, False, False, False,  True, False])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['bin_index_bits'][24478]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the result with a former British diplomat, whose bin representation agrees with Obama's in only 8 out of 16 places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22745</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Wynn_Normington_H...</td>\n",
       "      <td>Wynn Normington Hugh-Jones</td>\n",
       "      <td>sir wynn normington hughjones kb sometimes kno...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     URI  \\\n",
       "22745  <http://dbpedia.org/resource/Wynn_Normington_H...   \n",
       "\n",
       "                             name  \\\n",
       "22745  Wynn Normington Hugh-Jones   \n",
       "\n",
       "                                                    text  \n",
       "22745  sir wynn normington hughjones kb sometimes kno...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki[wiki['name']=='Wynn Normington Hugh-Jones']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0]\n",
      "4660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False,  True, False, False,  True,  True,\n",
       "        True, False,  True,  True, False, False,  True])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.array(model['bin_index_bits'][22745], dtype=int)) # list of 0/1's\n",
    "print(model['bin_indices'][22745]) # integer format\n",
    "model['bin_index_bits'][35817] == model['bin_index_bits'][22745]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about the documents in the same bin as Barack Obama? Are they necessarily more similar to Obama than Biden?  Let's look at which documents are in the same bin as the Barack Obama article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21426, 35817, 39426, 50261, 53937]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['table'][model['bin_indices'][35817]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four other documents that belong to the same bin. Which documents are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21426</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Mark_Boulware&gt;</td>\n",
       "      <td>Mark Boulware</td>\n",
       "      <td>mark boulware born 1948 is an american diploma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39426</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/John_Wells_(polit...</td>\n",
       "      <td>John Wells (politician)</td>\n",
       "      <td>sir john julius wells born 30 march 1925 is a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50261</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Francis_Longstaff&gt;</td>\n",
       "      <td>Francis Longstaff</td>\n",
       "      <td>francis a longstaff born august 3 1956 is an a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Madurai_T._Sriniv...</td>\n",
       "      <td>Madurai T. Srinivasan</td>\n",
       "      <td>maduraitsrinivasan is a wellknown figure in th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     URI  \\\n",
       "21426        <http://dbpedia.org/resource/Mark_Boulware>   \n",
       "39426  <http://dbpedia.org/resource/John_Wells_(polit...   \n",
       "50261    <http://dbpedia.org/resource/Francis_Longstaff>   \n",
       "53937  <http://dbpedia.org/resource/Madurai_T._Sriniv...   \n",
       "\n",
       "                          name  \\\n",
       "21426            Mark Boulware   \n",
       "39426  John Wells (politician)   \n",
       "50261        Francis Longstaff   \n",
       "53937    Madurai T. Srinivasan   \n",
       "\n",
       "                                                    text  \n",
       "21426  mark boulware born 1948 is an american diploma...  \n",
       "39426  sir john julius wells born 30 march 1925 is a ...  \n",
       "50261  francis a longstaff born august 3 1956 is an a...  \n",
       "53937  maduraitsrinivasan is a wellknown figure in th...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ids = list(model['table'][model['bin_indices'][35817]])\n",
    "doc_ids.remove(35817) # display documents other than Obama\n",
    "\n",
    "docs = wiki[wiki.index.isin(doc_ids)] # filter by id column\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that Joe Biden is much closer to Barack Obama than any of the four documents, even though Biden's bin representation differs from Obama's by 2 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mark Boulware'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.iloc[doc_id,:]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================= Cosine distance from Barack Obama\n",
      "Barack Obama - Joe Biden               : 0.703139\n",
      "Barack Obama - Mark Boulware           : 0.950867\n",
      "Barack Obama - John Wells (politician) : 0.975966\n",
      "Barack Obama - Francis Longstaff       : 0.978256\n",
      "Barack Obama - Madurai T. Srinivasan   : 0.993092\n"
     ]
    }
   ],
   "source": [
    "def cosine_distance(x, y):\n",
    "    xy = x.dot(y.T)\n",
    "    dist = xy/(norm(x)*norm(y))\n",
    "    return 1-dist[0,0]\n",
    "\n",
    "obama_tf_idf = corpus[35817,:]\n",
    "biden_tf_idf = corpus[24478,:]\n",
    "\n",
    "print('================= Cosine distance from Barack Obama')\n",
    "print('Barack Obama - {0:24s}: {1:f}'.format('Joe Biden',\n",
    "                                             cosine_distance(obama_tf_idf, biden_tf_idf)))\n",
    "for doc_id in doc_ids:\n",
    "    doc_tf_idf = corpus[doc_id,:]\n",
    "    print('Barack Obama - {0:24s}: {1:f}'.format(wiki.iloc[doc_id,:]['name'],\n",
    "                                                 cosine_distance(obama_tf_idf, doc_tf_idf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Moral of the story**. Similar data points will in general _tend to_ fall into _nearby_ bins, but that's all we can say about LSH. In a high-dimensional space such as text features, we often get unlucky with our selection of only a few random vectors such that dissimilar data points go into the same bin while similar data points fall into different bins. **Given a query document, we must consider all documents in the nearby bins and sort them according to their actual distances from the query.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the LSH model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first implement the logic for searching nearby neighbors, which goes like this:\n",
    "```\n",
    "1. Let L be the bit representation of the bin that contains the query documents.\n",
    "2. Consider all documents in bin L.\n",
    "3. Consider documents in the bins whose bit representation differs from L by 1 bit.\n",
    "4. Consider documents in the bins whose bit representation differs from L by 2 bits.\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain candidate bins that differ from the query bin by some number of bits, we use `itertools.combinations`, which produces all possible subsets of a given list. See [this documentation](https://docs.python.org/3/library/itertools.html#itertools.combinations) for details.\n",
    "```\n",
    "1. Decide on the search radius r. This will determine the number of different bits between the two vectors.\n",
    "2. For each subset (n_1, n_2, ..., n_r) of the list [0, 1, 2, ..., num_vector-1], do the following:\n",
    "   * Flip the bits (n_1, n_2, ..., n_r) of the query bin to produce a new bit vector.\n",
    "   * Fetch the list of documents belonging to the bin indexed by the new bit vector.\n",
    "   * Add those documents to the candidate set.\n",
    "```\n",
    "\n",
    "Each line of output from the following cell is a 3-tuple indicating where the candidate bin would differ from the query bin. For instance,\n",
    "```\n",
    "(0, 1, 3)\n",
    "```\n",
    "indicates that the candiate bin differs from the query bin in first, second, and fourth bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<itertools.combinations at 0x20bcd5b54a8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations(range(16),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n",
      "(0, 2)\n",
      "(0, 3)\n",
      "(0, 4)\n",
      "(0, 5)\n",
      "(0, 6)\n",
      "(0, 7)\n",
      "(0, 8)\n",
      "(0, 9)\n",
      "(0, 10)\n",
      "(0, 11)\n",
      "(0, 12)\n",
      "(0, 13)\n",
      "(0, 14)\n",
      "(0, 15)\n",
      "(1, 2)\n",
      "(1, 3)\n",
      "(1, 4)\n",
      "(1, 5)\n",
      "(1, 6)\n",
      "(1, 7)\n",
      "(1, 8)\n",
      "(1, 9)\n",
      "(1, 10)\n",
      "(1, 11)\n",
      "(1, 12)\n",
      "(1, 13)\n",
      "(1, 14)\n",
      "(1, 15)\n",
      "(2, 3)\n",
      "(2, 4)\n",
      "(2, 5)\n",
      "(2, 6)\n",
      "(2, 7)\n",
      "(2, 8)\n",
      "(2, 9)\n",
      "(2, 10)\n",
      "(2, 11)\n",
      "(2, 12)\n",
      "(2, 13)\n",
      "(2, 14)\n",
      "(2, 15)\n",
      "(3, 4)\n",
      "(3, 5)\n",
      "(3, 6)\n",
      "(3, 7)\n",
      "(3, 8)\n",
      "(3, 9)\n",
      "(3, 10)\n",
      "(3, 11)\n",
      "(3, 12)\n",
      "(3, 13)\n",
      "(3, 14)\n",
      "(3, 15)\n",
      "(4, 5)\n",
      "(4, 6)\n",
      "(4, 7)\n",
      "(4, 8)\n",
      "(4, 9)\n",
      "(4, 10)\n",
      "(4, 11)\n",
      "(4, 12)\n",
      "(4, 13)\n",
      "(4, 14)\n",
      "(4, 15)\n",
      "(5, 6)\n",
      "(5, 7)\n",
      "(5, 8)\n",
      "(5, 9)\n",
      "(5, 10)\n",
      "(5, 11)\n",
      "(5, 12)\n",
      "(5, 13)\n",
      "(5, 14)\n",
      "(5, 15)\n",
      "(6, 7)\n",
      "(6, 8)\n",
      "(6, 9)\n",
      "(6, 10)\n",
      "(6, 11)\n",
      "(6, 12)\n",
      "(6, 13)\n",
      "(6, 14)\n",
      "(6, 15)\n",
      "(7, 8)\n",
      "(7, 9)\n",
      "(7, 10)\n",
      "(7, 11)\n",
      "(7, 12)\n",
      "(7, 13)\n",
      "(7, 14)\n",
      "(7, 15)\n",
      "(8, 9)\n",
      "(8, 10)\n",
      "(8, 11)\n",
      "(8, 12)\n",
      "(8, 13)\n",
      "(8, 14)\n",
      "(8, 15)\n",
      "(9, 10)\n",
      "(9, 11)\n",
      "(9, 12)\n",
      "(9, 13)\n",
      "(9, 14)\n",
      "(9, 15)\n",
      "(10, 11)\n",
      "(10, 12)\n",
      "(10, 13)\n",
      "(10, 14)\n",
      "(10, 15)\n",
      "(11, 12)\n",
      "(11, 13)\n",
      "(11, 14)\n",
      "(11, 15)\n",
      "(12, 13)\n",
      "(12, 14)\n",
      "(12, 15)\n",
      "(13, 14)\n",
      "(13, 15)\n",
      "(14, 15)\n"
     ]
    }
   ],
   "source": [
    "num_vector = 16\n",
    "search_radius = 2\n",
    "\n",
    "for diff in combinations(range(num_vector), search_radius):\n",
    "    print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this output in mind, implement the logic for nearby bin search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_nearby_bins(query_bin_bits, table, search_radius=2, initial_candidates=set()):\n",
    "    \"\"\"\n",
    "    对于查找的数据点，找到与之将近的bins\n",
    "    \"\"\"\n",
    "    num_vector = len(query_bin_bits)\n",
    "    powers_of_two = 2**np.arange(num_vector-1, -1, -1)\n",
    "    \n",
    "    # 提供初始的邻近bins，默认为空\n",
    "    candidate_set = copy(initial_candidates)\n",
    "    \n",
    "    from itertools import combinations\n",
    "    # 找到与所在bin邻近的bins\n",
    "    for different_bits in combinations(range(num_vector), search_radius):       \n",
    "        alternate_bits = copy(query_bin_bits)\n",
    "        # 邻近bin相对位置的二进制值要与所在bin正好相反\n",
    "        for i in different_bits:\n",
    "            alternate_bits[i] = not query_bin_bits[i]        \n",
    "        # 将找到的邻近bin的二进制数转换为数字\n",
    "        nearby_bin = alternate_bits.dot(powers_of_two)\n",
    "        \n",
    "        # 将邻近bin中的数据添加到集中\n",
    "        if nearby_bin in table:\n",
    "            candidate_set = candidate_set | set(table[nearby_bin])\n",
    "            \n",
    "    return candidate_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**. Running the function with `search_radius=0` should yield the list of documents belonging to the same bin as the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test\n",
      "List of documents in the same bin as Obama: 35817, 21426, 53937, 39426, 50261\n"
     ]
    }
   ],
   "source": [
    "obama_bin_index = model['bin_index_bits'][35817] # bin index of Barack Obama\n",
    "candidate_set = search_nearby_bins(obama_bin_index, model['table'], search_radius=0)\n",
    "if candidate_set == set([35817, 21426, 53937, 39426, 50261]):\n",
    "    print('Passed test')\n",
    "else:\n",
    "    print('Check your code')\n",
    "print('List of documents in the same bin as Obama: 35817, 21426, 53937, 39426, 50261')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**. Running the function with `search_radius=1` adds more documents to the fore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed test\n"
     ]
    }
   ],
   "source": [
    "candidate_set = search_nearby_bins(obama_bin_index, model['table'], search_radius=1, initial_candidates=candidate_set)\n",
    "if candidate_set == set([39426, 38155, 38412, 28444, 9757, 41631, 39207, 59050, 47773, 53937, 21426, 34547,\n",
    "                         23229, 55615, 39877, 27404, 33996, 21715, 50261, 21975, 33243, 58723, 35817, 45676,\n",
    "                         19699, 2804, 20347]):\n",
    "    print('Passed test')\n",
    "else:\n",
    "    print('Check your code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**. Don't be surprised if few of the candidates look similar to Obama. This is why we add as many candidates as our computational budget allows and sort them by their distance to the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a function that can return all the candidates from neighboring bins. Next we write a function to collect all candidates and compute their true distance to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def query(query_data, model, k, max_search_radius):\n",
    "  \n",
    "    data = model['data']\n",
    "    table = model['table']\n",
    "    random_vectors = model['random_vectors']\n",
    "    num_vector = random_vectors.shape[1]\n",
    "        \n",
    "    # 计算所在bin\n",
    "    bin_index_bits = (query_data.dot(random_vectors) >= 0).flatten()\n",
    "\n",
    "    # 找到所有的查找点，包括所在bin和邻近bin\n",
    "    candidate_set = set()\n",
    "    for search_radius in range(max_search_radius+1):\n",
    "        candidate_set = search_nearby_bins(bin_index_bits, table, search_radius, initial_candidates=candidate_set)\n",
    "    \n",
    "    # 计算每个点的距离，并由高到低排序\n",
    "    nearest_neighbors = pd.DataFrame({'id' : list(candidate_set)})\n",
    "    candidates = data[np.array(list(candidate_set)),:]\n",
    "    from sklearn.metrics.pairwise import pairwise_distances \n",
    "    nearest_neighbors['distance'] = pairwise_distances(candidates, query_data, metric='cosine').flatten()\n",
    "    \n",
    "    # 返回前k个临近点和查找点的个数\n",
    "    return nearest_neighbors.sort_values('distance',ascending=True)[:k], len(candidate_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out with Obama:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify the documents, it's helpful to join this table with the Wikipedia table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>distance</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Barack Obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24478</td>\n",
       "      <td>0.703139</td>\n",
       "      <td>Joe Biden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56008</td>\n",
       "      <td>0.856848</td>\n",
       "      <td>Nathan Cullen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37199</td>\n",
       "      <td>0.874669</td>\n",
       "      <td>Barry Sullivan (lawyer)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40353</td>\n",
       "      <td>0.890034</td>\n",
       "      <td>Neil MacBride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9267</td>\n",
       "      <td>0.898377</td>\n",
       "      <td>Vikramaditya Khanna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55909</td>\n",
       "      <td>0.899340</td>\n",
       "      <td>Herman Cain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9165</td>\n",
       "      <td>0.900921</td>\n",
       "      <td>Raymond F. Clevenger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>57958</td>\n",
       "      <td>0.903003</td>\n",
       "      <td>Michael J. Malbin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>49872</td>\n",
       "      <td>0.909533</td>\n",
       "      <td>Lowell Barron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  distance                     name\n",
       "0  35817  0.000000             Barack Obama\n",
       "1  24478  0.703139                Joe Biden\n",
       "2  56008  0.856848            Nathan Cullen\n",
       "3  37199  0.874669  Barry Sullivan (lawyer)\n",
       "4  40353  0.890034            Neil MacBride\n",
       "5   9267  0.898377      Vikramaditya Khanna\n",
       "6  55909  0.899340              Herman Cain\n",
       "7   9165  0.900921     Raymond F. Clevenger\n",
       "8  57958  0.903003        Michael J. Malbin\n",
       "9  49872  0.909533            Lowell Barron"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(corpus[35817,:], model, k=10, max_search_radius=3)[0]\\\n",
    "            .merge(wiki[['name']].reset_index().rename(columns={'index':'id'}), on='id').sort_values('distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have shown that we have a working LSH implementation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with your LSH implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following sections we have implemented a few experiments so that you can gain intuition for how your LSH implementation behaves in different situations. This will help you understand the effect of searching nearby bins and the performance of LSH versus computing nearest neighbors using a brute force search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of nearby bin search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does nearby bin search affect the outcome of LSH? There are three variables that are affected by the search radius:\n",
    "* Number of candidate documents considered\n",
    "* Query time\n",
    "* Distance of approximate neighbors from the query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run LSH multiple times, each with different radii for nearby bin search. We will measure the three variables as discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URI</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35817</th>\n",
       "      <td>&lt;http://dbpedia.org/resource/Barack_Obama&gt;</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>barack hussein obama ii brk husen bm born augu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              URI          name  \\\n",
       "35817  <http://dbpedia.org/resource/Barack_Obama>  Barack Obama   \n",
       "\n",
       "                                                    text  \n",
       "35817  barack hussein obama ii brk husen bm born augu...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki[wiki['name']=='Barack Obama']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radius: 0\n",
      "      id  distance                     name\n",
      "0  35817  0.000000             Barack Obama\n",
      "1  21426  0.950867            Mark Boulware\n",
      "2  39426  0.975966  John Wells (politician)\n",
      "3  50261  0.978256        Francis Longstaff\n",
      "4  53937  0.993092    Madurai T. Srinivasan\n",
      "Radius: 1\n",
      "      id  distance                                   name\n",
      "0  35817  0.000000                           Barack Obama\n",
      "1  41631  0.947459                            Binayak Sen\n",
      "2  21426  0.950867                          Mark Boulware\n",
      "3  33243  0.951766                        Janice Lachance\n",
      "4  33996  0.960859                            Rufus Black\n",
      "5  28444  0.961081                       John Paul Phelan\n",
      "6  20347  0.974130                        Gianni De Fraja\n",
      "7  39426  0.975966                John Wells (politician)\n",
      "8  34547  0.978215  Nathan Murphy (Australian politician)\n",
      "9  50261  0.978256                      Francis Longstaff\n",
      "Radius: 2\n",
      "      id  distance                 name\n",
      "0  35817  0.000000         Barack Obama\n",
      "1  24478  0.703139            Joe Biden\n",
      "2   9267  0.898377  Vikramaditya Khanna\n",
      "3  55909  0.899340          Herman Cain\n",
      "4   6949  0.925713   Harrison J. Goldin\n",
      "5  23524  0.926398        Paul Bennecke\n",
      "6   5823  0.928498       Adeleke Mamora\n",
      "7  37262  0.934454           Becky Cain\n",
      "8  10121  0.936896         Bill Bradley\n",
      "9  54782  0.937809   Thomas F. Hartnett\n",
      "Radius: 3\n",
      "      id  distance                     name\n",
      "0  35817  0.000000             Barack Obama\n",
      "1  24478  0.703139                Joe Biden\n",
      "2  56008  0.856848            Nathan Cullen\n",
      "3  37199  0.874669  Barry Sullivan (lawyer)\n",
      "4  40353  0.890034            Neil MacBride\n",
      "5   9267  0.898377      Vikramaditya Khanna\n",
      "6  55909  0.899340              Herman Cain\n",
      "7   9165  0.900921     Raymond F. Clevenger\n",
      "8  57958  0.903003        Michael J. Malbin\n",
      "9  49872  0.909533            Lowell Barron\n",
      "Radius: 4\n",
      "      id  distance                name\n",
      "0  35817  0.000000        Barack Obama\n",
      "1  24478  0.703139           Joe Biden\n",
      "2  36452  0.833985        Bill Clinton\n",
      "3  24848  0.839407     John C. Eastman\n",
      "4  43155  0.840839         Goodwin Liu\n",
      "5  42965  0.849078     John O. Brennan\n",
      "6  56008  0.856848       Nathan Cullen\n",
      "7  38495  0.857574        Barney Frank\n",
      "8  18752  0.858899      Dan W. Reicher\n",
      "9   2092  0.874643  Richard Blumenthal\n",
      "Radius: 5\n",
      "      id  distance                     name\n",
      "0  35817  0.000000             Barack Obama\n",
      "1  24478  0.703139                Joe Biden\n",
      "2  38714  0.770561  Eric Stern (politician)\n",
      "3  46811  0.800197            Jeff Sessions\n",
      "4  14754  0.826854              Mitt Romney\n",
      "5  36452  0.833985             Bill Clinton\n",
      "6  40943  0.834535           Jonathan Alter\n",
      "7  55044  0.837013             Wesley Clark\n",
      "8  24848  0.839407          John C. Eastman\n",
      "9  43155  0.840839              Goodwin Liu\n",
      "Radius: 6\n",
      "      id  distance                     name\n",
      "0  35817  0.000000             Barack Obama\n",
      "1  24478  0.703139                Joe Biden\n",
      "2  38714  0.770561  Eric Stern (politician)\n",
      "3  44681  0.790926   Jesse Lee (politician)\n",
      "4  46811  0.800197            Jeff Sessions\n",
      "5  48693  0.809192              Artur Davis\n",
      "6  23737  0.810165        John D. McCormick\n",
      "7   4032  0.814555      Kenneth D. Thompson\n",
      "8  28447  0.823229           George W. Bush\n",
      "9  14754  0.826854              Mitt Romney\n",
      "Radius: 7\n",
      "      id  distance                     name\n",
      "0  35817  0.000000             Barack Obama\n",
      "1  24478  0.703139                Joe Biden\n",
      "2  38376  0.742982           Samantha Power\n",
      "3  57108  0.758358   Hillary Rodham Clinton\n",
      "4  38714  0.770561  Eric Stern (politician)\n",
      "5  44681  0.790926   Jesse Lee (politician)\n",
      "6  18827  0.798323             Henry Waxman\n",
      "7  46811  0.800197            Jeff Sessions\n",
      "8  48693  0.809192              Artur Davis\n",
      "9  23737  0.810165        John D. McCormick\n",
      "Radius: 8\n",
      "      id  distance                     name\n",
      "0  35817  0.000000             Barack Obama\n",
      "1  24478  0.703139                Joe Biden\n",
      "2  38376  0.742982           Samantha Power\n",
      "3  57108  0.758358   Hillary Rodham Clinton\n",
      "4  38714  0.770561  Eric Stern (politician)\n",
      "5  44681  0.790926   Jesse Lee (politician)\n",
      "6  18827  0.798323             Henry Waxman\n",
      "7  46811  0.800197            Jeff Sessions\n",
      "8  48693  0.809192              Artur Davis\n",
      "9  23737  0.810165        John D. McCormick\n",
      "Radius: 9\n",
      "      id  distance                     name\n",
      "0  35817  0.000000             Barack Obama\n",
      "1  24478  0.703139                Joe Biden\n",
      "2  38376  0.742982           Samantha Power\n",
      "3  57108  0.758358   Hillary Rodham Clinton\n",
      "4  38714  0.770561  Eric Stern (politician)\n",
      "5  46140  0.784678             Robert Gibbs\n",
      "6  44681  0.790926   Jesse Lee (politician)\n",
      "7  18827  0.798323             Henry Waxman\n",
      "8  46811  0.800197            Jeff Sessions\n",
      "9  39357  0.809051              John McCain\n",
      "Radius: 10\n",
      "      id  distance                     name\n",
      "0  35817  0.000000             Barack Obama\n",
      "1  24478  0.703139                Joe Biden\n",
      "2  38376  0.742982           Samantha Power\n",
      "3  57108  0.758358   Hillary Rodham Clinton\n",
      "4  38714  0.770561  Eric Stern (politician)\n",
      "5  46140  0.784678             Robert Gibbs\n",
      "6  44681  0.790926   Jesse Lee (politician)\n",
      "7  18827  0.798323             Henry Waxman\n",
      "8   2412  0.799466          Joe the Plumber\n",
      "9  46811  0.800197            Jeff Sessions\n",
      "Radius: 11\n",
      "      id  distance                     name\n",
      "0  35817  0.000000             Barack Obama\n",
      "1  24478  0.703139                Joe Biden\n",
      "2  38376  0.742982           Samantha Power\n",
      "3  57108  0.758358   Hillary Rodham Clinton\n",
      "4  38714  0.770561  Eric Stern (politician)\n",
      "5  46140  0.784678             Robert Gibbs\n",
      "6  44681  0.790926   Jesse Lee (politician)\n",
      "7  18827  0.798323             Henry Waxman\n",
      "8   2412  0.799466          Joe the Plumber\n",
      "9  46811  0.800197            Jeff Sessions\n",
      "Radius: 12\n",
      "      id  distance                     name\n",
      "0  35817  0.000000             Barack Obama\n",
      "1  24478  0.703139                Joe Biden\n",
      "2  38376  0.742982           Samantha Power\n",
      "3  57108  0.758358   Hillary Rodham Clinton\n",
      "4  38714  0.770561  Eric Stern (politician)\n",
      "5  46140  0.784678             Robert Gibbs\n",
      "6   6796  0.788039              Eric Holder\n",
      "7  44681  0.790926   Jesse Lee (politician)\n",
      "8  18827  0.798323             Henry Waxman\n",
      "9   2412  0.799466          Joe the Plumber\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-049d26875ca1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     result, num_candidates = query(corpus[35817,:], model, k=10,\n\u001b[1;32m---> 10\u001b[1;33m                                    max_search_radius=max_search_radius)\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mquery_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-77-e6d1486848bb>\u001b[0m in \u001b[0;36mquery\u001b[1;34m(query_data, model, k, max_search_radius)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mcandidate_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msearch_radius\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_search_radius\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mcandidate_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch_nearby_bins\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbin_index_bits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_radius\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_candidates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcandidate_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# 计算每个点的距离，并由高到低排序\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-2e2f4ee76c4d>\u001b[0m in \u001b[0;36msearch_nearby_bins\u001b[1;34m(query_bin_bits, table, search_radius, initial_candidates)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# Convert the new bit vector to an integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mnearby_bin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malternate_bits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpowers_of_two\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# Fetch the list of documents belonging to the bin indexed by the new bit vector.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_candidates_history = []\n",
    "query_time_history = []\n",
    "max_distance_from_query_history = []\n",
    "min_distance_from_query_history = []\n",
    "average_distance_from_query_history = []\n",
    "\n",
    "for max_search_radius in range(17):\n",
    "    start=time.time()\n",
    "    result, num_candidates = query(corpus[35817,:], model, k=10,\n",
    "                                   max_search_radius=max_search_radius)\n",
    "    end=time.time()\n",
    "    query_time = end-start\n",
    "    \n",
    "    print('Radius:', max_search_radius)\n",
    "    print(result.merge(wiki[['name']].reset_index().rename(columns={'index':'id'}), on='id').sort_values('distance'))\n",
    "    \n",
    "    average_distance_from_query = result['distance'][1:].mean()\n",
    "    max_distance_from_query = result['distance'][1:].max()\n",
    "    min_distance_from_query = result['distance'][1:].min()\n",
    "    \n",
    "    num_candidates_history.append(num_candidates)\n",
    "    query_time_history.append(query_time)\n",
    "    average_distance_from_query_history.append(average_distance_from_query)\n",
    "    max_distance_from_query_history.append(max_distance_from_query)\n",
    "    min_distance_from_query_history.append(min_distance_from_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the top 10 query results become more relevant as the search radius grows. Let's plot the three variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(num_candidates_history, linewidth=4)\n",
    "plt.xlabel('Search radius')\n",
    "plt.ylabel('# of documents searched')\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(query_time_history, linewidth=4)\n",
    "plt.xlabel('Search radius')\n",
    "plt.ylabel('Query time (seconds)')\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(average_distance_from_query_history, linewidth=4, label='Average of 10 neighbors')\n",
    "plt.plot(max_distance_from_query_history, linewidth=4, label='Farthest of 10 neighbors')\n",
    "plt.plot(min_distance_from_query_history, linewidth=4, label='Closest of 10 neighbors')\n",
    "plt.xlabel('Search radius')\n",
    "plt.ylabel('Cosine distance of neighbors')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some observations:\n",
    "* As we increase the search radius, we find more neighbors that are a smaller distance away.\n",
    "* With increased search radius comes a greater number documents that have to be searched. Query time is higher as a consequence.\n",
    "* With sufficiently high search radius, the results of LSH begin to resemble the results of brute-force search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**. What was the smallest search radius that yielded the correct nearest neighbor, namely Joe Biden?\n",
    "\n",
    "\n",
    "**Quiz Question**. Suppose our goal was to produce 10 approximate nearest neighbors whose average distance from the query document is within 0.01 of the average for the true 10 nearest neighbors. For Barack Obama, the true 10 nearest neighbors are on average about 0.77. What was the smallest search radius for Barack Obama that produced an average distance of 0.78 or better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality metrics for neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above analysis is limited by the fact that it was run with a single query, namely Barack Obama. We should repeat the analysis for the entirety of data. Iterating over all documents would take a long time, so let us randomly choose 10 documents for our analysis.\n",
    "\n",
    "For each document, we first compute the true 25 nearest neighbors, and then run LSH multiple times. We look at two metrics:\n",
    "\n",
    "* Precision@10: How many of the 10 neighbors given by LSH are among the true 25 nearest neighbors?\n",
    "* Average cosine distance of the neighbors from the query\n",
    "\n",
    "Then we run LSH multiple times with different search radii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def brute_force_query(vec, data, k):\n",
    "    num_data_points = data.shape[0]\n",
    "    \n",
    "    # Compute distances for ALL data points in training set\n",
    "    nearest_neighbors = graphlab.SFrame({'id':range(num_data_points)})\n",
    "    nearest_neighbors['distance'] = pairwise_distances(data, vec, metric='cosine').flatten()\n",
    "    \n",
    "    return nearest_neighbors.topk('distance', k, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will run LSH with multiple search radii and compute the quality metrics for each run. Allow a few minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_radius = 17\n",
    "precision = {i:[] for i in xrange(max_radius)}\n",
    "average_distance  = {i:[] for i in xrange(max_radius)}\n",
    "query_time  = {i:[] for i in xrange(max_radius)}\n",
    "\n",
    "np.random.seed(0)\n",
    "num_queries = 10\n",
    "for i, ix in enumerate(np.random.choice(corpus.shape[0], num_queries, replace=False)):\n",
    "    print('%s / %s' % (i, num_queries))\n",
    "    ground_truth = set(brute_force_query(corpus[ix,:], corpus, k=25)['id'])\n",
    "    # Get the set of 25 true nearest neighbors\n",
    "    \n",
    "    for r in xrange(1,max_radius):\n",
    "        start = time.time()\n",
    "        result, num_candidates = query(corpus[ix,:], model, k=10, max_search_radius=r)\n",
    "        end = time.time()\n",
    "\n",
    "        query_time[r].append(end-start)\n",
    "        # precision = (# of neighbors both in result and ground_truth)/10.0\n",
    "        precision[r].append(len(set(result['id']) & ground_truth)/10.0)\n",
    "        average_distance[r].append(result['distance'][1:].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(range(1,17), [np.mean(average_distance[i]) for i in xrange(1,17)], linewidth=4, label='Average over 10 neighbors')\n",
    "plt.xlabel('Search radius')\n",
    "plt.ylabel('Cosine distance')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(range(1,17), [np.mean(precision[i]) for i in xrange(1,17)], linewidth=4, label='Precison@10')\n",
    "plt.xlabel('Search radius')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(range(1,17), [np.mean(query_time[i]) for i in xrange(1,17)], linewidth=4, label='Query time')\n",
    "plt.xlabel('Search radius')\n",
    "plt.ylabel('Query time (seconds)')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observations for Barack Obama generalize to the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of number of random vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now turn our focus to the remaining parameter: the number of random vectors. We run LSH with different number of random vectors, ranging from 5 to 20. We fix the search radius to 3.\n",
    "\n",
    "Allow a few minutes for the following cell to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = {i:[] for i in xrange(5,20)}\n",
    "average_distance  = {i:[] for i in xrange(5,20)}\n",
    "query_time = {i:[] for i in xrange(5,20)}\n",
    "num_candidates_history = {i:[] for i in xrange(5,20)}\n",
    "ground_truth = {}\n",
    "\n",
    "np.random.seed(0)\n",
    "num_queries = 10\n",
    "docs = np.random.choice(corpus.shape[0], num_queries, replace=False)\n",
    "\n",
    "for i, ix in enumerate(docs):\n",
    "    ground_truth[ix] = set(brute_force_query(corpus[ix,:], corpus, k=25)['id'])\n",
    "    # Get the set of 25 true nearest neighbors\n",
    "\n",
    "for num_vector in xrange(5,20):\n",
    "    print('num_vector = %s' % (num_vector))\n",
    "    model = train_lsh(corpus, num_vector, seed=143)\n",
    "    \n",
    "    for i, ix in enumerate(docs):\n",
    "        start = time.time()\n",
    "        result, num_candidates = query(corpus[ix,:], model, k=10, max_search_radius=3)\n",
    "        end = time.time()\n",
    "        \n",
    "        query_time[num_vector].append(end-start)\n",
    "        precision[num_vector].append(len(set(result['id']) & ground_truth[ix])/10.0)\n",
    "        average_distance[num_vector].append(result['distance'][1:].mean())\n",
    "        num_candidates_history[num_vector].append(num_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(range(5,20), [np.mean(average_distance[i]) for i in xrange(5,20)], linewidth=4, label='Average over 10 neighbors')\n",
    "plt.xlabel('# of random vectors')\n",
    "plt.ylabel('Cosine distance')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(range(5,20), [np.mean(precision[i]) for i in xrange(5,20)], linewidth=4, label='Precison@10')\n",
    "plt.xlabel('# of random vectors')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(range(5,20), [np.mean(query_time[i]) for i in xrange(5,20)], linewidth=4, label='Query time (seconds)')\n",
    "plt.xlabel('# of random vectors')\n",
    "plt.ylabel('Query time (seconds)')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(7,4.5))\n",
    "plt.plot(range(5,20), [np.mean(num_candidates_history[i]) for i in xrange(5,20)], linewidth=4,\n",
    "         label='# of documents searched')\n",
    "plt.xlabel('# of random vectors')\n",
    "plt.ylabel('# of documents searched')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.rcParams.update({'font.size':16})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a similar trade-off between quality and performance: as the number of random vectors increases, the query time goes down as each bin contains fewer documents on average, but on average the neighbors are likewise placed farther from the query. On the other hand, when using a small enough number of random vectors, LSH becomes very similar brute-force search: Many documents appear in a single bin, so searching the query bin alone covers a lot of the corpus; then, including neighboring bins might result in searching all documents, just as in the brute-force approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
